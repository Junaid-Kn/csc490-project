# -*- coding: utf-8 -*-
"""CSC490.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DAHHho754uqFNZTo88B14cUMAYpUz30c
"""

# clone github repository with the training data
# !git clone https://github.com/Junaid-Kn/csc490-project.git

import os, torch, random
from torchvision import transforms
import pandas as pd
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

from train_model import train
from test_model import test
from CustomDataset import CustomDataset
from StudentCNNModel import StudentCNNModel
from UnetModel import UNetModel
from inference import run_inference
from DoubleConv import DoubleConv

# Define image transformation
transform = transforms.Compose([
    transforms.Resize((256, 256)),  # Resize if needed
    transforms.ToTensor(),          # Convert to tensor
])

##############################################################
#################### SPLITTING THE DATASET ###################
##############################################################
# Paths to the masked and target images
masked_path = "../Inspaint_data/Train_Data/Masked"
target_path = "../Inspaint_data/Train_Data/Target"

# Get all target images and pair them with their corresponding mask images
target_images = sorted([f for f in os.listdir(target_path) if f.endswith(('.jpg', '.png'))])
print(f"Total target images: {len(target_images)}")
paired_images = [(os.path.join(target_path, img), os.path.join(masked_path, img.replace("target", "mask")))
                 for img in target_images if os.path.exists(os.path.join(masked_path, img.replace("target", "mask")))]
print(f"Total valid image-mask pairs: {len(paired_images)}")

# Decide training and test split ratio
total_size = len(paired_images)
training_set_size = int(0.9 * total_size) # 0.5 is 50% of the paired_images
test_set_size = total_size - training_set_size
print(f"Total size: {total_size}")
print(f"Train-test split {training_set_size}:{test_set_size}")

# Shuffle the paired images and split into training and test sets
random.shuffle(paired_images)
training_set = paired_images[:training_set_size]
test_set = paired_images[training_set_size:]
len(training_set)

# Save the sampled training and testing pairs to corresponding CSVs
df = pd.DataFrame(training_set, columns=["Target_Image", "Masked_Image"])
df.to_csv("../sampled_training_pairs.csv", index=False)
df = pd.DataFrame(test_set, columns=["Target_Image", "Masked_Image"])
df.to_csv("../sampled_test_pairs.csv", index=False)
print("Saved sampled image-mask pairs to 'sampled_pairs.csv'")

# Create CustomDataset objects from the saved training and testing sets
training_dataset = CustomDataset("../sampled_training_pairs.csv", transform=transform)
test_dataset = CustomDataset("../sampled_test_pairs.csv", transform=transform)
target, mask = training_dataset[0]
print(target.shape, mask.shape) # Check the shape of the first image and mask pair

# Create DataLoader for batching and shuffling
dataloader = DataLoader(training_dataset, batch_size=16, shuffle=False, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)
for batch in dataloader:
    target_batch, mask_batch = batch
    print("Batch Target Shape:", target_batch.shape)
    print("Batch Mask Shape:", mask_batch.shape)
    break  # Exit after one batch check



# Display a few images and masks from the dataset (UNCOMMENT IF NEEDED)
"""
fig, ax = plt.subplots(1, 3, figsize=(18, 4))  # Create three subplots

for i in range(10):
    random_index = random.randint(0, len(dataloader.dataset) - 1)  # Get random index from dataset
    image, mask = dataloader.dataset[random_index]  # Get image and mask from dataset
    image, mask = image.unsqueeze(0), mask.unsqueeze(0)  # Add batch dimension

    # Convert grayscale to RGB if necessary
    if image.shape[1] == 1:
        image = image.repeat(1, 3, 1, 1)  # Convert grayscale to RGB

    mask = mask[:, 0:1, :, :]  # Ensure mask has 1 channel

    # Display the first image (original)
    ax[0].imshow(image.squeeze().permute(1, 2, 0))  # Convert from CHW to HWC format for RGB
    ax[0].set_title("Original Image")
    ax[0].axis("off")  # Hide axis

    # Display the second image (mask)
    ax[1].imshow(mask.squeeze(), cmap="gray")  # Mask is grayscale
    ax[1].set_title("Mask")
    ax[1].axis("off")

    # Create masked image
    masked_image = image * (1 - mask)  # Apply the mask to the original image
    ax[2].imshow(masked_image.squeeze().permute(1, 2, 0))  # Convert from CHW to HWC format for RGB
    ax[2].set_title("Masked Image")
    ax[2].axis("off")

    # Print shape of image and mask data
    print("Image Shape:", image.shape)
    print("Mask Shape:", mask.shape)

plt.show()  # Ensure the plot is displayed
"""

##############################################################
#################### TRAINING AND TESTING ####################
##############################################################
# Check if GPU is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = UNetModel()  # Ensure this model is defined

# Load model weights if available other train from scratch
try:
    model.load_state_dict(torch.load("../unet_optimized_model.pth", map_location=device))
    print("Model weights loaded successfully.")
except FileNotFoundError:
    print("No saved model found, starting training from scratch.")
    trained_model, losses = train(model, dataloader, epochs=10, device=device)
    test_loss = test(model, test_loader, device)
    print(f"Final Avg Test Loss: {test_loss:.4f}")
    model.load_state_dict(torch.load("../unet_optimized_model.pth", map_location=device))
    
model.to(device)
model.eval()
print("Model loaded successfully!")

#############################################################
######################### INFERENCE #########################
#############################################################
# Get a random index from the test_loader
random_index = random.randint(0, len(test_loader.dataset) - 1)
print("Random Index:", random_index)
# Get the corresponding image and mask from the dataset
image, mask = test_loader.dataset[random_index]

# Ensure image and mask are in the correct format (single sample)
image, mask = image.unsqueeze(0), mask.unsqueeze(0)  # Add batch dimension

# Fix shape issues for image and mask
if image.shape[1] == 1:
    image = image.repeat(1, 3, 1, 1)  # Convert grayscale to RGB
mask = mask[:, 0:1, :, :]  # Ensure mask has 1 channel

# Run inference
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
output_image, masked_image = run_inference(model, image, mask, device)  # Get both outputs

# Debugging output
print("Image shape:", image.shape)  # Should be [1, 3, 256, 256] (batch, channels, height, width)
print("Mask shape:", mask.shape)    # Should be [1, 1, 256, 256] (batch, channels, height, width)

# Plot results
fig, ax = plt.subplots(1, 4, figsize=(15, 4))  # Changed to 1x5 for extra plot

# Plot original image
ax[0].imshow(image.squeeze().permute(1, 2, 0))  # Image: squeeze batch and permute channels for plotting
ax[0].set_title("Original Image")

# Plot mask
ax[1].imshow(mask.squeeze(), cmap="gray")  # Mask: squeeze batch dimension for plotting
ax[1].set_title("Mask")

# Plot masked image
ax[2].imshow(masked_image.squeeze().permute(1, 2, 0))  # Masked image
ax[2].set_title("Masked Image")

# Plot inpainted image
ax[3].imshow(output_image.squeeze().permute(1, 2, 0))  # Inpainted image
ax[3].set_title("Inpainted Image")

plt.show()